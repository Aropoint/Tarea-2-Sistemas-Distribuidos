#!/bin/bash

CSV_LOCAL="/data/datos.csv"
HDFS_DIR="/input"
HDFS_PATH="$HDFS_DIR/datos.csv"

# FunciÃ³n para subir el archivo
upload_to_hdfs() {
    echo "â¬†ï¸ Subiendo archivo a HDFS..."
    hdfs dfs -put -f "$CSV_LOCAL" "$HDFS_PATH"
    echo "ğŸ“ƒ Listando archivos en $HDFS_DIR:"
    hdfs dfs -ls "$HDFS_DIR"
    echo "âœ… Proceso de subida completo."
}

# VerificaciÃ³n inicial
echo "ğŸ“„ Verificando existencia del archivo CSV local: $CSV_LOCAL"
if [ ! -f "$CSV_LOCAL" ]; then
  echo "âŒ Archivo CSV no encontrado en $CSV_LOCAL. Esperando..."
  exit 1
fi

echo "ğŸ”Œ Probando conexiÃ³n a HDFS..."
until hdfs dfs -ls /; do
    echo "ğŸ”„ Esperando que HDFS estÃ© listo..."
    sleep 5
done

echo "ğŸ“ Verificando existencia del directorio en HDFS: $HDFS_DIR"
if ! hdfs dfs -test -d "$HDFS_DIR"; then
  echo "ğŸ“‚ Directorio no existe. CreÃ¡ndolo..."
  hdfs dfs -mkdir -p "$HDFS_DIR"
else
  echo "ğŸ“‚ Directorio ya existe."
fi

# Subir inicialmente
upload_to_hdfs

# Monitorear cambios (opcional)
echo "ğŸ‘€ Monitoreando cambios en el archivo CSV..."
while true; do
    inotifywait -e modify,create "$CSV_LOCAL"
    echo "ğŸ”„ Archivo modificado. Volviendo a subir..."
    upload_to_hdfs
    
    # AquÃ­ podrÃ­as agregar el procesamiento con Pig
    echo "ğŸ· Procesando con Pig..."
    pig -x mapreduce -f /path/to/your/script.pig
done