#!/bin/bash

# Configuraci√≥n
HADOOP_HOME=/opt/hadoop
PIG_HOME=/opt/pig
DATA_DIR=/data
HDFS_INPUT=/input
HDFS_OUTPUT=/output
PIG_SCRIPT=/scripts/process_waze_alerts.pig
CSV_FILE=datos_clean.json
HDFS_FILE=waze_data.json

# 1. Iniciar servicios SSH y Hadoop con verificaci√≥n expl√≠cita
echo "‚öôÔ∏è Iniciando servicios..."
sudo service ssh start

# Configuraci√≥n cr√≠tica para Hadoop en Docker
echo "üîß Configurando Hadoop para entorno Docker..."
sed -i 's/<\/configuration>/<property><name>dfs.client.use.datanode.hostname<\/name><value>false<\/value><\/property><\/configuration>/' $HADOOP_HOME/etc/hadoop/hdfs-site.xml

# Formatear HDFS solo si no existe
echo "üóÑÔ∏è Formateando HDFS (si es necesario)..."
if [ ! -d "$HADOOP_HOME/data/namenode" ]; then
  $HADOOP_HOME/bin/hdfs namenode -format -force -nonInteractive
fi

# Iniciar servicios Hadoop con m√°s logs
echo "üöÄ Iniciando DFS..."
$HADOOP_HOME/sbin/start-dfs.sh

# Espera cr√≠tica para datanodes - Versi√≥n mejorada
echo "‚è≥ Esperando registro de DataNodes..."
DATANODE_READY=false
for i in {1..10}; do
  if $HADOOP_HOME/bin/hdfs dfsadmin -report 2>&1 | grep -q "Live datanodes"; then
    DATANODE_READY=true
    break
  fi
  echo "Intento $i/10: DataNodes no listos, esperando..."
  sleep 10
done

if [ "$DATANODE_READY" = false ]; then
  echo "‚úó Error: No se detectaron DataNodes activos despu√©s de 10 intentos"
  echo "‚ö†Ô∏è Mostrando reporte de estado:"
  $HADOOP_HOME/bin/hdfs dfsadmin -report
  exit 1
fi

echo "üöÄ Iniciando YARN..."
$HADOOP_HOME/sbin/start-yarn.sh

# 2. Configurar estructura HDFS con verificaci√≥n
echo "üìö Configurando estructura HDFS..."
$HADOOP_HOME/bin/hdfs dfs -mkdir -p $HDFS_INPUT || echo "‚ö†Ô∏è No se pudo crear $HDFS_INPUT"
$HADOOP_HOME/bin/hdfs dfs -mkdir -p $HDFS_OUTPUT || echo "‚ö†Ô∏è No se pudo crear $HDFS_OUTPUT"
$HADOOP_HOME/bin/hdfs dfs -chmod -R 755 $HDFS_INPUT
$HADOOP_HOME/bin/hdfs dfs -chmod -R 755 $HDFS_OUTPUT

# 3. Esperar archivo CSV con timeout
echo "üîç Esperando archivo CSV..."
CSV_TIMEOUT=60
CSV_WAITED=0
while [ ! -f "$DATA_DIR/$CSV_FILE" ] && [ $CSV_WAITED -lt $CSV_TIMEOUT ]; do
  echo "‚è≥ Esperando que $CSV_FILE est√© disponible... ($CSV_WAITED/$CSV_TIMEOUT segundos)"
  sleep 5
  CSV_WAITED=$((CSV_WAITED + 5))
done

if [ ! -f "$DATA_DIR/$CSV_FILE" ]; then
  echo "‚úó Error: Archivo $CSV_FILE no disponible despu√©s de $CSV_TIMEOUT segundos"
  exit 1
fi

# 4. Subir archivo a HDFS con verificaci√≥n mejorada
MAX_RETRIES=5
RETRY_COUNT=0
UPLOAD_SUCCESS=false

while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$UPLOAD_SUCCESS" = false ]; do
  echo "‚¨ÜÔ∏è Subiendo archivo a HDFS (Intento $((RETRY_COUNT+1))/$MAX_RETRIES)..."
  
  # Verificar espacio en HDFS
  HDFS_SPACE=$($HADOOP_HOME/bin/hdfs dfs -df | awk '{print $4}' | tail -1)
  FILE_SIZE=$(du -b "$DATA_DIR/$CSV_FILE" | awk '{print $1}')
  
  if [ "$HDFS_SPACE" -lt "$FILE_SIZE" ]; then
    echo "‚úó Espacio insuficiente en HDFS (Necesario: $FILE_SIZE, Disponible: $HDFS_SPACE)"
    exit 1
  fi

  # Intento de subida
  $HADOOP_HOME/bin/hdfs dfs -put -f "$DATA_DIR/$CSV_FILE" "$HDFS_INPUT/$HDFS_FILE"
  
  if [ $? -eq 0 ]; then
    HDFS_SIZE=$($HADOOP_HOME/bin/hdfs dfs -du -s "$HDFS_INPUT/$HDFS_FILE" | awk '{print $1}')
    LOCAL_SIZE=$(du -b "$DATA_DIR/$CSV_FILE" | awk '{print $1}')

    if [ "$HDFS_SIZE" -eq "$LOCAL_SIZE" ]; then
      echo "‚úì Archivo subido correctamente ($HDFS_SIZE bytes)"
      UPLOAD_SUCCESS=true
    else
      echo "‚úó Los tama√±os no coinciden (HDFS: $HDFS_SIZE vs Local: $LOCAL_SIZE)"
      $HADOOP_HOME/bin/hdfs dfs -rm -f "$HDFS_INPUT/$HDFS_FILE"
    fi
  else
    echo "‚úó Fall√≥ el intento $((RETRY_COUNT+1))"
    $HADOOP_HOME/bin/hdfs dfs -rm -f "$HDFS_INPUT/$HDFS_FILE" 2>/dev/null
  fi

  RETRY_COUNT=$((RETRY_COUNT+1))
  sleep 10
done

if [ "$UPLOAD_SUCCESS" = false ]; then
  echo "‚úó Error: No se pudo subir el archivo despu√©s de $MAX_RETRIES intentos"
  echo "‚ö†Ô∏è Estado de HDFS:"
  $HADOOP_HOME/bin/hdfs dfsadmin -report
  exit 1
fi

# 5. Configurar entorno Pig
echo "‚öôÔ∏è Configurando entorno Pig..."
export PIG_CLASSPATH=$HADOOP_HOME/etc/hadoop:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/*

# 6. Esperar que YARN est√© listo con verificaci√≥n
echo "‚è≥ Esperando que YARN est√© listo..."
YARN_READY=false
for i in {1..10}; do
  if $HADOOP_HOME/bin/yarn node -list 2>/dev/null | grep -q "RUNNING"; then
    YARN_READY=true
    break
  fi
  echo "Intento $i/10: YARN no listo, esperando..."
  sleep 10
done

if [ "$YARN_READY" = false ]; then
  echo "‚úó Error: YARN no est√° listo despu√©s de 10 intentos"
  echo "‚ö†Ô∏è Mostrando estado de YARN:"
  $HADOOP_HOME/bin/yarn node -list
  exit 1
fi

# 7. Ejecutar script Pig
echo "üê∑ Ejecutando script Pig..."
$PIG_HOME/bin/pig -x mapreduce -f "$PIG_SCRIPT"
PIG_EXIT_CODE=$?

if [ $PIG_EXIT_CODE -ne 0 ]; then
  echo "‚úó Error en la ejecuci√≥n de Pig (C√≥digo: $PIG_EXIT_CODE)"
  # 8. Mantener contenedor activo
echo "‚úì Procesamiento completado. Contenedor activo..."
tail -f /dev/null
fi

# 8. Mantener contenedor activo
echo "‚úì Procesamiento completado. Contenedor activo..."
tail -f /dev/null